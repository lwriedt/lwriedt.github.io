# Election Manipulation

In most countries, there seems to be a growing trend among the population to consume news and information from social media platforms. News and information moves from traditional media like print and tv, where content in liberal countries is somewhat vetted, to technology platforms where content is largely unregulated and news feed priority is influenced by both traffic as well as algorithms and user profiling.

The Cambridge Analytics incident and technology developments like big data processing for training AI algorithms and user profiling as well as algorithm developments give reason to look closer to what actually happens at popular elections in a country.

It is becoming easier, cheaper and faster to create and distribute misinformation content. Is this a real concern, and what are the trends? Some of the questions I have are

## Players

*Who are the players exploiting technology platforms for election manipulation?*

Are they in-country players with a political agenda? Or are they external players like adversial countries or corporations?
For example, Russia has vested interest in any elections in Ukraine, but also business lobbies like energy, food or tobacco may have an interest in certain election outcomes.


## Distribution

*What are the methods of creating misinformation content, selecting receptive audiences and delivering the content?*

Social Media platforms offer an abundance of tools to profile and segment audiences, that can be influenced; created for business purposes but readily available for political campaigns. While recognizing there are transparent, legitimate uses, i.e. political parties promoting their agenda or single politicians, the very same tools can be misused for opaque, hidden agendas.

Specially, we see Twitter Bots being used to influence professional media people like journalists, and manipulative content then spills over to traditional media. And Twitter Bots comes in abundance, are easy to reuse and are effectively allowed to operate.


## Content

*What content is effective to manipulate opinions and election outcomes, and how is it made?*

With GPT tools like Google Bard, Microsoft Bing and ChatGPT, as well as visual generators like DALL-E or DreamStudio, it has become very easy to create compelling messages to promote conspiracy theories and fake information.

Fake visual content like pictures or videos of persons/events that never happened (deepfake) are very effective. Some are made provocative to highlight the risks, but some are used for manipulation purposes. But also, text is becoming more compelling with GPT tools, which can produce narratives that sounds compelling and in a style fitting a target audience.

This also makes it harder to discover, remove or mark content designed to manipulate elections.
Manipulation campaigns are also often using websites or homepages that enforce the messages and add credibility. Chatrooms add to the mix and enforce echo chambers.


## Regulation

*How strong are the independent regulation of social media platforms?*

Facebook has its Oversight Board, Google has a Content Policy for search and Twitter has Elon Musk. But does this work? Are content truthful, fair and balanced?
How are selv-regulation enforced?
Are there any outside forces in play, like the coming EU AI Act or even GDPR or frameworks from entities like OECD?


**(C) Lars Wriedt, May 2023**
